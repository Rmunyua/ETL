{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from config import token\n",
    "import requests\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 845 entries, 0 to 844\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       845 non-null    object\n",
      " 1   1       845 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 13.3+ KB\n",
      "Salt Lake City\n",
      "Salt Lake City\n",
      "UT\n",
      "UT\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348 entries, 0 to 347\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       348 non-null    object\n",
      " 1   1       348 non-null    object\n",
      " 2   2       348 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 8.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41 entries, 0 to 40\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       41 non-null     object\n",
      " 1   1       41 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 784.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# get the location list\n",
    "tk = {'token': token}\n",
    "\n",
    "# search city\n",
    "params=\"locationcategoryid=CITY&sortfield=name&sortorder=desc&limit=1000&offset=\"\n",
    "base_url= \"https://www.ncdc.noaa.gov/cdo-web/api/v2/locations\"\n",
    "offset=1\n",
    "\n",
    "\n",
    "city_list=[]\n",
    "while True:\n",
    "    cur_params = params + str(offset)\n",
    "    r = requests.get(base_url, params = cur_params, headers=tk)\n",
    "    location_list = r.json() \n",
    "    if len(location_list) == 0:\n",
    "        break\n",
    "    city_name = []\n",
    "    for i in location_list['results']:\n",
    "        if \"CITY:US\" not in i['id']:\n",
    "            continue\n",
    "        city_name.append([i['id'], i['name']])\n",
    "    offset += 1000\n",
    "    city_list.extend(city_name)\n",
    "    \n",
    "# all US cities from noaa   \n",
    "df = pd.DataFrame.from_dict(city_list)\n",
    "df.info()\n",
    "df.to_csv(\"all_cities.csv\")\n",
    "    \n",
    "# shared cities from both Employment and Temperature datasets\n",
    "city_list_msa = pd.read_csv(\"MSA.csv\")[[\"Unified State\", \"Unified City\"]]\n",
    "shared_cities=[]\n",
    "diff_cities=[]\n",
    "for s1, c1 in city_list_msa.values.tolist():\n",
    "    found = 0\n",
    "    for id, cname in city_list:\n",
    "        c2 = cname.split(',')[0]\n",
    "        s2 = cname.split(' ')[-2]\n",
    "        if s1 == s2 and c1 == c2:\n",
    "            shared_cities.append([id, c2, s2])\n",
    "            found = 1\n",
    "            break\n",
    "    if found != 1:\n",
    "        diff_cities.append([s1, c1])\n",
    "    \n",
    "df = pd.DataFrame.from_dict(shared_cities)\n",
    "df.info()\n",
    "df.to_csv(\"shared_cities.csv\")\n",
    "df = pd.DataFrame.from_dict(diff_cities)\n",
    "df.info()\n",
    "df.to_csv(\"diff_cities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search weather\n",
    "params = 'datasetid=GSOM'\n",
    "date_range = '&datatypeid=TMAX&datatypeid=TMIN&datatypeid=TAVG&startdate=2019-01-01&enddate=2019-12-31&units=standard&limit=1000&offset='\n",
    "base_url= \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n",
    "\n",
    "temp_city={}\n",
    "for id, city, state in shared_cities:\n",
    "    cur_params = params + \"&locationid=\" + id\n",
    "    cur_params = cur_params + date_range\n",
    "    key = city + \", \" + state\n",
    "    data = []\n",
    "    offset = 1\n",
    "    while True:\n",
    "        cur_params = cur_params + str(offset)\n",
    "        r = requests.get(base_url, params = cur_params, headers=tk)\n",
    "        data_list = r.json() \n",
    "        if len(data_list) == 0:\n",
    "            break\n",
    "        offset += 1000\n",
    "        temp = [[i['date'], i['station'], i['datatype'], i['value']] for i in data_list['results']] \n",
    "        data.extend(temp)\n",
    "    temp_city[key] = data\n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output json file\n",
    "import json\n",
    "with open(\"temp_per_city.json\", 'w') as outfile:\n",
    "    json.dump(temp_city, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2019-01-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 44.8],\n",
      " ['2019-01-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 53.9],\n",
      " ['2019-01-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 35.7],\n",
      " ['2019-02-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 51.9],\n",
      " ['2019-02-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 59.8],\n",
      " ['2019-02-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 44.0],\n",
      " ['2019-03-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 53.4],\n",
      " ['2019-03-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 63.2],\n",
      " ['2019-03-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 43.6],\n",
      " ['2019-04-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 64.6],\n",
      " ['2019-04-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 75.8],\n",
      " ['2019-04-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 53.4],\n",
      " ['2019-05-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 73.9],\n",
      " ['2019-05-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 83.6],\n",
      " ['2019-05-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 64.2],\n",
      " ['2019-06-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 77.4],\n",
      " ['2019-06-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 86.8],\n",
      " ['2019-06-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 67.9],\n",
      " ['2019-07-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 81.0],\n",
      " ['2019-07-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 90.7],\n",
      " ['2019-07-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 71.4],\n",
      " ['2019-08-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 81.1],\n",
      " ['2019-08-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 92.2],\n",
      " ['2019-08-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 70.0],\n",
      " ['2019-09-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 80.5],\n",
      " ['2019-09-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 93.8],\n",
      " ['2019-09-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 67.3],\n",
      " ['2019-11-01T00:00:00', 'GHCND:USC00013154', 'TAVG', 50.0],\n",
      " ['2019-11-01T00:00:00', 'GHCND:USC00013154', 'TMAX', 62.5],\n",
      " ['2019-11-01T00:00:00', 'GHCND:USC00013154', 'TMIN', 37.5]]\n"
     ]
    }
   ],
   "source": [
    "# load from json and test one city\n",
    "import json\n",
    "with open(\"temp_per_city.json\", 'r') as infile:\n",
    "    tc = json.load(infile)\n",
    "\n",
    "pprint(tc[\"Gadsden, AL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gadsden, AL has no record for 2019-10-01\n",
      "Gadsden, AL has no record for 2019-12-01\n",
      "Chico, CA has no record for 2019-12-01\n",
      "Ocala, FL has no record for 2019-10-01\n",
      "Elizabethtown, KY has no record for 2019-01-01\n",
      "Elizabethtown, KY has no record for 2019-02-01\n",
      "Elizabethtown, KY has no record for 2019-03-01\n",
      "Elizabethtown, KY has no record for 2019-04-01\n",
      "Elizabethtown, KY has no record for 2019-05-01\n",
      "Elizabethtown, KY has no record for 2019-06-01\n",
      "Elizabethtown, KY has no record for 2019-07-01\n",
      "Elizabethtown, KY has no record for 2019-08-01\n",
      "Elizabethtown, KY has no record for 2019-09-01\n",
      "Elizabethtown, KY has no record for 2019-10-01\n",
      "Elizabethtown, KY has no record for 2019-11-01\n",
      "Elizabethtown, KY has no record for 2019-12-01\n",
      "Owensboro, KY has no record for 2019-01-01\n",
      "Owensboro, KY has no record for 2019-02-01\n",
      "Owensboro, KY has no record for 2019-03-01\n",
      "Owensboro, KY has no record for 2019-04-01\n",
      "Owensboro, KY has no record for 2019-05-01\n",
      "Owensboro, KY has no record for 2019-06-01\n",
      "Owensboro, KY has no record for 2019-07-01\n",
      "Owensboro, KY has no record for 2019-08-01\n",
      "Owensboro, KY has no record for 2019-09-01\n",
      "Owensboro, KY has no record for 2019-10-01\n",
      "Owensboro, KY has no record for 2019-11-01\n",
      "Owensboro, KY has no record for 2019-12-01\n",
      "Hammond, LA has no record for 2019-01-01\n",
      "Hammond, LA has no record for 2019-02-01\n",
      "Hammond, LA has no record for 2019-03-01\n",
      "Hammond, LA has no record for 2019-04-01\n",
      "Hammond, LA has no record for 2019-05-01\n",
      "Hammond, LA has no record for 2019-06-01\n",
      "Hammond, LA has no record for 2019-07-01\n",
      "Hammond, LA has no record for 2019-08-01\n",
      "Hammond, LA has no record for 2019-09-01\n",
      "Hammond, LA has no record for 2019-10-01\n",
      "Hammond, LA has no record for 2019-11-01\n",
      "Hammond, LA has no record for 2019-12-01\n",
      "Bloomsburg, PA has no record for 2019-12-01\n",
      "Hilton Head Island, SC has no record for 2019-01-01\n",
      "Hilton Head Island, SC has no record for 2019-02-01\n",
      "Hilton Head Island, SC has no record for 2019-03-01\n",
      "Hilton Head Island, SC has no record for 2019-04-01\n",
      "Hilton Head Island, SC has no record for 2019-05-01\n",
      "Hilton Head Island, SC has no record for 2019-06-01\n",
      "Hilton Head Island, SC has no record for 2019-07-01\n",
      "Hilton Head Island, SC has no record for 2019-08-01\n",
      "Hilton Head Island, SC has no record for 2019-09-01\n",
      "Hilton Head Island, SC has no record for 2019-10-01\n",
      "Hilton Head Island, SC has no record for 2019-11-01\n",
      "Hilton Head Island, SC has no record for 2019-12-01\n",
      "Sumter, SC has no record for 2019-10-01\n",
      "Lynchburg, VA has no record for 2019-11-01\n"
     ]
    }
   ],
   "source": [
    "# get the average temperature for each month at a specific city\n",
    "import csv\n",
    "month=[\"2019-01-01\", \"2019-02-01\", \"2019-03-01\",\"2019-04-01\",\"2019-05-01\",\"2019-06-01\",\\\n",
    "       \"2019-07-01\",\"2019-08-01\",\"2019-09-01\",\"2019-10-01\",\"2019-11-01\",\"2019-12-01\"]\n",
    "\n",
    "with open(\"aver_temp_per_city.csv\", 'w') as outfile:\n",
    "    csvwriter = csv.writer(outfile)\n",
    "    csvwriter.writerow(['city', 'Jan', 'Feb', 'Mar', 'Apr','May', 'Jun', 'Jul', 'Aug','Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    rows=[]\n",
    "    for city in tc: # for each city\n",
    "        aver_per_month = [0]*12 # each city has 12 data\n",
    "        count_per_month = [0]*12 # each data is average of all TAVG from stations\n",
    "        for record in tc[city]: # each city's json \n",
    "            for m_index in range(0, len(month)): # m_index represents each month\n",
    "                if month[m_index] in record[0]: # if month belongs to 0 under each city's json\n",
    "                    aver_per_month[m_index] += float(record[3]) # add this ave to previous sum\n",
    "                    count_per_month[m_index] += 1 # count 1 to previous count_sum\n",
    "                    break # break the inner for loop if found the month info\n",
    "        #city, sum and count are available now\n",
    "        city_data = [city] # assign city row into the file\n",
    "        for i in range(0, len(aver_per_month)): # assign each month's average temp to sequential 12 columns\n",
    "            if count_per_month[i] == 0:\n",
    "                print(city + \" has no record for \" + month[i]) #figure out missing avg\n",
    "                city_data.append('N/A')\n",
    "                continue\n",
    "            city_data.append('{:.2f}'.format(aver_per_month[i] / count_per_month[i]))# formating\n",
    "        rows.append(city_data)\n",
    "    csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
